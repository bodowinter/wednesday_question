---
title: "Experiment 3 - Analysis"
author: "Bodo Winter"
date: "7/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preliminaries:

Load packages:

```{r}
library(tidyverse)
library(brms)
```

Load in data:

```{r}
header <- readLines('../data/E3_mismatch.csv', n = 1)
E3 <- read_csv('../data/E3_mismatch.csv', skip = 2,
               col_names = FALSE)
colnames(E3) <- unlist(str_split(header, ','))
```

Rename relevant columns:

```{r}
E3 <- rename(E3,
             Control = MathQuestion,
             Age = age,
             Gender = gender,
             Handedness = handedness,
             NativeLanguage = language,
             Condition = `DO-BR-FL_10`,
             Comments = OpenEnded,
             Notice = GestureNotice,
             ViewN = VideoNTimes,
             ViewYes = VideoCompletion,
             IP = V6,
             StartTime = V8,
             FinishTime = V9)
```

Get all_responses:

```{r}
# Initialize empty column for responses:

E3$Response <- NA

# The relevant columns all have '_resp':

these_cols <- str_detect(colnames(E3), 'E3_')

# The relevant columns all have '_resp':

for (i in 1:nrow(E3)) {
  this <- unlist(E3[i, these_cols])
  names(this) <- c()
  if (!all(is.na(this))) {
    E3[i, ]$Response <- this[!is.na(this)]
  }
  }
```

There's some issue with the file, let's get rid of the respective columns:

Select subset of dataframe with relevant columns:

```{r}
E3 <- select(E3,
             ViewYes:NativeLanguage, IP, Notice, Condition,  StartTime, FinishTime, Response)
```

Exclude those partials that did not respond and report loss. For proper reporting (since there will be several rounds of exclusion), it makes sense to create a tibble:

```{r}
# Original tibble:

excl_tib <- tibble(N = nrow(E3), Type = 'Original')

# Those that didn't respond:

E3 <- filter(E3, !is.na(Response))

# New tibble to keep track of exclusions:

new_tib <- tibble(N = nrow(E3), Type = 'after partials')
excl_tib <- bind_rows(excl_tib, new_tib)
```

Exclude those that are duplicated responses (from the same IP):

```{r}
# Those that didn't respond:

these_IPs <- filter(E3, duplicated(IP)) %>% pull(IP)
E3 <- filter(E3, !(IP %in% these_IPs))

# New tibble to keep track of exclusions:

new_tib <- tibble(N = nrow(E3), Type = 'after duplicates')
excl_tib <- bind_rows(excl_tib, new_tib)
```

Get rid of non-native speakers:

```{r}
# Vector of things to exclude:

excludes <- c('Polish', 'German', 'Spanish', 'Bulgarian')

# Exclude:

E3 <- filter(E3, !(NativeLanguage %in% excludes))

# New tibble to keep track of exclusions:

new_tib <- tibble(N = nrow(E3), Type = 'after non-natives')
excl_tib <- bind_rows(excl_tib, new_tib)
```

Get rid of people who couldn't view the videos:

```{r}
# Exclude:

E3 <- filter(E3, ViewYes == 'Yes')

# Get rid of those that report to have had a viewing problem:

excludes <- c("the video skipped the first time through",
              "The video was a bit choppy but it was manageable",
              "it stopped midway so I had to restart it again to hear the full version again completely",
              "video cuts abruptly",
              "Just I couldn't hear it over my children being loud",
              "the video seemed choppy and low res and the audio was off aswell",
              "it buffered a bit",
              "Near the beginning, I noticed a bit of an issue with buffering, which is the reason for my answer being unsure.",
              "yeah, loaded slow and paused in the middle to buffer",
              "The video got stuck at one point before continuing on",
              "The video stopped to buffer twice, which may or may not have been part of the experiment, but I was able to hear all of the spoken words.",
              "Video loaded very slowly and was very choppy",
              "had  to get my headphones",
              "The video paused to load in the middle of the sentence which made it difficult to understand.",
              "Yes, the sound didn't work",
              "buffered the first time towards the end")

# Exclude these:

exclude_ids <- which(E3$VideoIssues %in% excludes)
E3 <- E3[-exclude_ids, ]

# New tibble to keep track of exclusions:

new_tib <- tibble(N = nrow(E3), Type = 'after viewing problems')
excl_tib <- bind_rows(excl_tib, new_tib)
```

Process viewing times:

```{r}
# Make it into lowercase for easier processing:

E3 <- mutate(E3, ViewN = str_to_lower(ViewN))

# Create a table that matches responses to counts:

ViewN <- c('1', '1 time', 'once', 'once.', 'one', 'one time', 'only once',
           '2', '2 times', 'twice', 'two',
           '3', '4', '5')
ViewCount = c(1, 1, 1, 1, 1, 1, 1,
              2, 2, 2, 2,
              3, 4, 5)
key <- tibble(ViewN, ViewCount)

# Merge these counts into the data frame:

E3 <- left_join(E3, key)
```

Assess whether the viewing times depend on condition:

```{r}
E3 %>% group_by(Condition) %>%
  summarize(sum = sum(ViewCount, na.rm = TRUE))
```

This time around there is! The forward language and backward gesture has 10 less. Let's check this with a quick and dirty Chi-square test:

```{r}
E3 %>% group_by(Condition) %>%
  summarize(sum = sum(ViewCount, na.rm = TRUE)) %>% 
  pull(sum) %>% chisq.test()
```

Nope.

Create the Monday/Friday column:

```{r}
E3 <- mutate(E3, Response = str_to_lower(Response))

E3$RespClean <- NA
E3[str_detect(E3$Response, 'monday'), ]$RespClean <- 'monday'
E3[str_detect(E3$Response, 'friday'), ]$RespClean <- 'friday'

# Exclude those that responded neither monday nor friday:

E3 <- filter(E3, !is.na(RespClean))

# New tibble to keep track of exclusions:

new_tib <- tibble(N = nrow(E3), Type = 'after wrong-day responders')
excl_tib <- bind_rows(excl_tib, new_tib)
```

Code condition column:

```{r}
conditions <- str_split(E3$Condition, pattern = '_', simplify = TRUE)

E3$Language <- conditions[, 2]
E3$Direction <- conditions[, 3]
```

Get rid of the original response column:

```{r}
E3 <- mutate(E3,
             Response = RespClean) %>% 
  select(-RespClean)
```

For plotting make it so that the Response factor is "monday", then "friday" (easier: from left to right).

```{r}
E3 <- mutate(E3,
             Response = str_to_title(Response),
             Response = factor(Response, levels = c('Monday', 'Friday')))
```

Change the labels in the Gesture and Language columns to make them better for plotting, and order factors for plotting:

```{r}
E3 <- mutate(E3,
             Direction = ifelse(Direction == 'BG', 'backward', 'forward'),
             DirectionPlot = str_c(Direction, '\ngesture'),
             Direction = factor(Direction,
                                levels = c('backward', 'forward')),
             DirectionPlot = factor(DirectionPlot,
                                    levels = c('backward\ngesture', 'forward\ngesture')),
             Language = ifelse(Language == 'BL', 'backward language', 'forward language'),
             Language = factor(Language))
```

Overview of exclusions:

```{r}
excl_tib$Exclusions <- c(0, abs(diff(excl_tib$N)))
excl_tib$Prop <- NA
for (i in 2:nrow(excl_tib)) {
  excl_tib[i, ]$Prop <- excl_tib[i, ]$N / excl_tib[i - 1, ]$N
}
excl_tib <- mutate(excl_tib, Prop = 1 - Prop)
excl_tib
```

And the overall exclusion:

```{r}
excl_tib[1, ]$N - excl_tib[nrow(excl_tib), ]$N
(excl_tib[1, ]$N - excl_tib[nrow(excl_tib), ]$N) / excl_tib[1, ]$N
```


Check the comprehension question:

```{r}
all(E1$Control == 13)
```

What's reported in the paper is the following, the number of participants that are actually participants of the study (N = 319) compared to the 232 participants that are included in the analysis.

```{r}
orig <- filter(excl_tib, Type == 'after duplicates')$N
final <- filter(excl_tib, Type == 'after wrong-day responders')$N
orig - final
1 - (final / orig)
```

What does the total sample consist of in terms of demographics?

```{r}
table(E2$Gender)
mean(as.numeric(E2$Age), na.rm = TRUE)
range(as.numeric(E2$Age), na.rm = TRUE)
```



## Descriptive stats and visualizations:

First, how many were aware of the gestures?

```{r}
E3 %>% count(Notice, sort = TRUE)
```

Lots of them.

Tabulations of the main result:

```{r}
E3 %>% count(Response)
with(E3, prop.table(table(E3$Response)))
```

Overall many more Monday responses.

Effect of direction:

```{r}
with(E3, table(Direction, Response))
round(with(E3, prop.table(table(Direction, Response), 1)), 2)
```

Effect of language:

```{r}
with(E3, table(Language, Response))
round(with(E3, prop.table(table(Language, Response), 1)), 2)
```

More Monday responses when the language is backwards.

```{r}
mycounts <- E3 %>% count(Language, DirectionPlot, Response)
```

Zero Friday for "backward language" and "backward direction".

Let's add this zero for plotting:

```{r}
mytib <- tibble(Language = 'backward language',
                DirectionPlot = 'backward\ngesture',
                Response = 'Friday',
                n = 0) %>% 
  mutate(Language = factor(Language, levels = c('backward language', 'forward language')),
         DirectionPlot = factor(DirectionPlot, levels = c('backward\ngesture', 'forward\ngesture')))
mycounts <- bind_rows(mycounts, mytib)
```


## Publication ready stacked bar plot:

Stacked bar plot with percentages:

```{r, fig.width = 9, fig.height = 5}
mycounts %>%
  spread(Response, n, fill = 0) %>%
  mutate(Sum = Monday + Friday,
         Monday = Monday / Sum,
         Friday = Friday / Sum) %>%
  select(-Sum) %>%
  gather(key = 'Response', value = 'n',
         -(Language:DirectionPlot)) %>%
  mutate(Response = factor(Response,
                           levels = c('Monday', 'Friday'))) %>%
  rename(Proportion = n) %>% 
  ggplot(aes(x = DirectionPlot, y = Proportion, fill = Response)) +
  geom_bar(stat = 'identity', col = 'black',
           position = position_stack(reverse = TRUE),
           width = 0.5) + 
  scale_fill_manual(values = c('#FDE725FF', '#21908CFF')) +
  theme_minimal() +
  theme(legend.position = 'right') +
  facet_wrap(~Language) +
  labs(title = 'Monday/Friday responses by\nLanguage Direction and Gesture Direction',
       caption = str_c('N = ', nrow(E3), ', Amazon Mechanical Turk')) +
  ylab('Proportion\n') +
  xlab('') +
  theme(plot.title = element_text(face = 'bold', size = 20, hjust = 0.5),
        axis.title = element_text(face = 'bold', size = 24),
        axis.text.x = element_text(face = 'bold', size = 20),
        axis.text.y = element_text(face = 'bold', size = 12),
        strip.text.x = element_text(face = 'bold', size = 20),
        plot.caption = element_text(size = 14),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank())
ggsave('../figures/experiment3.png', width = 9, height = 6)
```

## Is there any indication of the direction effect being modulated by likeability?

Convert the scales for likeability:

```{r}
E3 <- mutate(E3,
       Likeability = ifelse(Likeability == 'strongly disagree', '1', Likeability),
       Likeability = ifelse(Likeability == 'slightly disagree', '2', Likeability),
       Likeability = ifelse(Likeability == 'slightly agree', '3', Likeability),
       Likeability = ifelse(Likeability == 'strongly agree', '4', Likeability),
       Likeability = as.numeric(Likeability),
       Warm = ifelse(Warm == 'strongly disagree', '1', Warm),
       Warm = ifelse(Warm == 'slightly disagree', '2', Warm),
       Warm = ifelse(Warm == 'slightly agree', '3', Warm),
       Warm = ifelse(Warm == 'strongly agree', '4', Warm),
       Warm = as.numeric(Warm),
       Friendly = ifelse(Friendly == 'strongly disagree', '1', Friendly),
       Friendly = ifelse(Friendly == 'slightly disagree', '2', Friendly),
       Friendly = ifelse(Friendly == 'slightly agree', '3', Friendly),
       Friendly = ifelse(Friendly == 'strongly agree', '4', Friendly),
       Friendly = as.numeric(Friendly),
       Approachability = ifelse(Approachability == 'strongly disagree', '1', Approachability),
       Approachability = ifelse(Approachability == 'slightly disagree', '2', Approachability),
       Approachability = ifelse(Approachability == 'slightly agree', '3', Approachability),
       Approachability = ifelse(Approachability == 'strongly agree', '4', Approachability),
       Approachability = as.numeric(Approachability))
```

Create sum scores:

```{r}
E3 <- mutate(E3,
             LikeScale = Friendly + Warm + Approachability + Likeability,
             LikeScale_c = LikeScale - mean(LikeScale))
```

Next, how do they correspond to the responses. For this, it'll be easiest to categorize people into high and low LikeScale based on median split ... (this is just for visualization purposes).

```{r}
# Median split for Likeability:

E3$Like_cat <- NA
E3[E3$LikeScale > 12 & !is.na(E3$LikeScale), ]$Like_cat <- 'high'
E3[E3$LikeScale < 12 & !is.na(E3$LikeScale), ]$Like_cat <- 'low'
```

Visualize the main perspective-relevant result (direction) as a function of likeability of the person:

```{r}
E3 %>%
  count(Direction, Like_cat, Response) %>%
  filter(!is.na(Like_cat)) %>% 
  ggplot(aes(x = Direction, y = n, fill = Response)) +
  geom_bar(stat = 'identity', col = 'black',
           position = 'dodge') + 
  scale_fill_viridis_d(option = 'D', direction = -1) +
  theme_minimal() +
  theme(legend.position = 'top') +
  facet_wrap(~Like_cat)
```

## Model this with logistic regression:

Sum-code the categorical predictors:

```{r}
contrasts(E3$Direction) <- contr.sum(2) / 2 * -1
contrasts(E3$Language) <- contr.sum(2) / 2 * -1
```

Set the parameters for a Bayesian analysis:

```{r}
# For parallel processing:

options(mc.cores=parallel::detectCores())

# For handling the MCMC sampling:

my_controls <- list(adapt_delta = 0.99,
                    max_treedepth = 13)
```

Set regularizing priors on betas:

```{r}
my_priors <- c(prior(normal(0, 1), class = b))
```

Specify and run the model:

```{r, message = FALSE}
E3_mdl <- brm(Response ~ Direction * Language,
              data = E3,
              family = bernoulli,
              init = 0,
              chains = 8,
              seed = 42,
              warmup = 2000,
              iter = 8000,
              prior = my_priors,
              control = my_controls)
save(E3_mdl, file = '../models/E3_mdl.RData')
```

Summarize the model:

```{r}
summary(E3_mdl)
```

Plot marginal effects:

```{r}
marginal_effects(E3_mdl, effects = 'Direction:Language')
```

Check how many of the posteriors were in the predicted direction:

```{r}
# To aid interpretation:

levels(E3$Response)
contrasts(E3$Direction)

# Extract posterior samples:

mypost <- posterior_samples(E3_mdl)

# Posterior probability of the language effect being above 0:

sum(mypost$b_Direction1 > 0) / nrow(mypost)

# Same for the language effect:

sum(mypost$b_Language1 > 0) / nrow(mypost)

# Same for the hand shape effect:

sum(mypost$'b_Direction1:Language1' > 0) / nrow(mypost)

# What is the probability of the language effect being stronger than the gesture effect?

sum(mypost$b_Language1 > mypost$b_Direction1) / nrow(mypost)

```

## Check influence of likeability on direction:

Model with likeability/AQ * direction interaction.

```{r}
E3_social_mdl <- brm(Response ~ Direction * LikeScale_c,
              data = E3,
              family = bernoulli,
              init = 0,
              chains = 8,
              seed = 42,
              warmup = 2000,
              iter = 8000,
              prior = my_priors,
              control = my_controls)
save(E3_social_mdl, file = '../models/E3_social_mdl.RData')
```

Check:

```{r}
summary(E3_social_mdl)
```

Check the posterior values:

```{r}
mypost <- posterior_samples(E3_social_mdl)

# Direction * likeability interaction:

sum(mypost$'b_Direction1:LikeScale_c' > 0) / nrow(mypost)
```

Marginal effects:

```{r, fig.width = 8, fig.height = 6}
marginal_effects(E3_social_mdl, effects = 'Direction:LikeScale_c')
```

Save the results outside for subsequent meta-analysis:

```{r}
write_csv(E3, '../data/cleaned_data/E3_cleaned.csv')
```

This completes this analysis.


